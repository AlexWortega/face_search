{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!pip install facenet-pytorch"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting facenet-pytorch\n",
      "  Downloading facenet_pytorch-2.5.2-py3-none-any.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 3.9 MB/s \n",
      "\u001b[?25hCollecting torchvision\n",
      "  Using cached torchvision-0.12.0-cp38-cp38-manylinux1_x86_64.whl (21.0 MB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from facenet-pytorch) (2.25.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from facenet-pytorch) (1.20.3)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from facenet-pytorch) (8.2.0)\n",
      "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->facenet-pytorch) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision->facenet-pytorch) (4.0.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/lib/python3/dist-packages (from requests->facenet-pytorch) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->facenet-pytorch) (1.26.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests->facenet-pytorch) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->facenet-pytorch) (2021.5.30)\n",
      "\u001b[31mERROR: rudolph 0.0.1rc0 has requirement einops~=0.3.2, but you'll have einops 0.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: rudolph 0.0.1rc0 has requirement more-itertools~=8.10.0, but you'll have more-itertools 8.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: rudolph 0.0.1rc0 has requirement transformers~=4.10.2, but you'll have transformers 4.6.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: rudalle 0.4.0 has requirement einops~=0.3.2, but you'll have einops 0.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: rudalle 0.4.0 has requirement more-itertools~=8.10.0, but you'll have more-itertools 8.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: rudalle 0.4.0 has requirement transformers~=4.10.2, but you'll have transformers 4.6.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: clip-ods 0.0.1rc2 has requirement opencv-python~=4.5.1.48, but you'll have opencv-python 4.5.4.60 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: clip-ods 0.0.1rc2 has requirement regex~=2021.4.4, but you'll have regex 2022.1.18 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: clip-ods 0.0.1rc2 has requirement torch~=1.7.1, but you'll have torch 1.11.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: clip-ods 0.0.1rc2 has requirement torchvision~=0.8.2, but you'll have torchvision 0.12.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: torchvision, facenet-pytorch\n",
      "Successfully installed facenet-pytorch-2.5.2 torchvision-0.12.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install git+https://github.com/sajjjadayobi/FaceLib.git"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# If required, create a face detection pipeline using MTCNN:\n",
    "mtcnn = MTCNN(image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True).to(device)\n",
    "\n",
    "# Create an inception resnet (in eval mode):\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').to(device).eval()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from PIL import Image\n",
    "\n",
    "def _get_box(img):\n",
    "    bbx, prob = mtcnn.detect(img)\n",
    "    return bbx\n",
    "    \n",
    "\n",
    "def _cosine(e1,e2):\n",
    "    cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    return cos(e1, e2)\n",
    "\n",
    "def _get_embeddings(img):\n",
    "    \n",
    "\n",
    "\n",
    "    img_cropped = mtcnn(img).to(device)\n",
    "    #print(img_cropped)\n",
    "    img_embedding = resnet(img_cropped.unsqueeze(0))\n",
    "\n",
    "    return img_embedding\n",
    "\n",
    "# Or, if using for VGGFace2 classification\n",
    "#resnet.classify = True\n",
    "#img_probs = resnet(img_cropped.unsqueeze(0))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "img1 = Image.open('faces/face1.jpeg')\n",
    "img2 = Image.open('Снимок экрана 2022-04-06 в 14.00.14 Small.jpeg')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "img1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "\n",
    "\n",
    "\n",
    "def gender_age(pil_image):\n",
    "    cv2_image = np.array(pil_image) \n",
    "    faces, _, _, _ = face_detector.detect_align(cv2_image)\n",
    "\n",
    "    genders, ages = age_gender_detector.detect(faces)\n",
    "    return genders, ages"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "from AgeGenderEstimator: weights loaded\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "gender_age(img1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(['Female'], [26])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gender_age(img2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "emb1 = _get_embeddings(img1)\n",
    "emb2 = _get_embeddings(img2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "_cosine(emb1,emb2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.5652], grad_fn=<DivBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}