{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "!pip freeze > req.txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install git+https://github.com/sajjjadayobi/FaceLib.git\n",
    "!pip install facenet-pytorch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from facelib import FaceDetector, AgeGenderEstimator\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "face_detector = FaceDetector()\n",
    "age_gender_detector = AgeGenderEstimator()\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "mtcnn = MTCNN(image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True).to(device)\n",
    "\n",
    "\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').to(device).eval()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from PIL import Image\n",
    "\n",
    "def _get_box(img):\n",
    "    bbx, prob = mtcnn.detect(img)\n",
    "    return bbx\n",
    "    \n",
    "\n",
    "def _cosine(e1,e2):\n",
    "    cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    return cos(e1, e2)\n",
    "\n",
    "def _get_embeddings(img):\n",
    "    img_cropped = mtcnn(img).to(device)\n",
    "    #print(img_cropped)\n",
    "    img_embedding = resnet(img_cropped.unsqueeze(0))\n",
    "\n",
    "    return img_embedding\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img1 = Image.open('faces/face1.jpeg')\n",
    "img2 = Image.open('Снимок экрана 2022-04-06 в 14.00.14 Small.jpeg')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def gender_age(pil_image):\n",
    "    cv2_image = np.array(pil_image) \n",
    "    faces, _, _, _ = face_detector.detect_align(cv2_image)\n",
    "\n",
    "    genders, ages = age_gender_detector.detect(faces)\n",
    "    return genders, ages"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "from AgeGenderEstimator: weights loaded\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "gender_age(img1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(['Female'], [26])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "gender_age(img2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(['Female'], [32])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "emb1 = _get_embeddings(img1)\n",
    "emb2 = _get_embeddings(img2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "_cosine(emb1,emb2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.5652], grad_fn=<DivBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}